{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping the EU clinical trial dataset\n",
    "This code shows how to scrape only the ICD-10 Diseases of the nervous system (minus inflammatory diseases of the CNS) due to my research focus.\n",
    "However, all disease htmls are available as a .csv file in gitlab and the principle is the same, just change the initial .csv to whichever disease area(s) you would like the EU Clinical trial protocols for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string\n",
    "\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the HTMLs from the HTML column in the .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_df.loc[:,'EudraCT_No']\n",
    "\n",
    "ns_df.dropna(subset=['EudraCT_No'], inplace=True)\n",
    "\n",
    "eudract_list = ns_df['EudraCT_No'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_eudract = str(eudract_list)\n",
    "len(str_eudract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD eudract number into url to identify individual protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlList = []\n",
    "\n",
    "for eudract_no in eudract_list:\n",
    "   urlList.append(\"https://www.clinicaltrialsregister.eu/ctr-search/trial/\"+str_eudract+\"/results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(urlList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Characteristics dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics_df = pd.DataFrame(columns=['EudraCT_No', 'Title', 'Phase', 'Objective', 'End_date','Sample_size', '1ry_endpoint', 'endpoint_description', 'Treatment', 'LT_followup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eudract_add = pd.DataFrame({'EudraCT_No': eudract_list})\n",
    "characteristics_df = pd.concat([eudract_add, characteristics_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(characteristics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add characteristics into the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for z in range (0, len(urlList)): \n",
    "    page = requests.get(urlList[z])\n",
    "    surrogate_soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    h1_list = surrogate_soup.find_all('h1')\n",
    "\n",
    "    first = True\n",
    "\n",
    "    title_list = []\n",
    "\n",
    "    \n",
    "    for heading in h1_list:\n",
    "        if \"Results:\" in heading.text:\n",
    "            a,b,c = heading.text.partition('Results:')\n",
    "            title_list.append(c.strip()) #Phase is incorporated into this part\n",
    "            phase = c.lower().split('phase') \n",
    "            if len(phase) > 1:\n",
    "                print(\"Phase \"+phase[1].split(' ')[1].translate(str.maketrans('','',string.punctuation)))\n",
    "                all_characteristics_df.iloc[idx,2] = phase[1].split(' ')[1].translate(str.maketrans('','',string.punctuation))\n",
    "                print(idx)\n",
    "            else:\n",
    "                all_characteristics_df.iloc[idx,2] = 0\n",
    "            idx = idx +1\n",
    "\n",
    "    for i, title in enumerate(title_list):\n",
    "        if title:\n",
    "            all_characteristics_df.iloc[z,1] = title\n",
    "           \n",
    "\n",
    "# Trial objectives \n",
    "    obj_list = []\n",
    "    \n",
    "    for m_obj in surrogate_soup.find_all('td', class_='labelColumn'): \n",
    "        if 'Main objective of the trial' in m_obj.text:\n",
    "            v_obj = m_obj.find_next('td', class_='valueColumn')\n",
    "            print(m_obj)\n",
    "            print(v_obj)\n",
    "            if v_obj:\n",
    "                o_text = v_obj.div.get_text(strip=True)\n",
    "                obj_list.append(o_text)\n",
    "            \n",
    "        if len(obj_list) ==1:\n",
    "            all_characteristics_df.iloc[z,3] = obj_list[0]\n",
    "        else:\n",
    "            all_characteristics_df.iloc[z,3] = 0;\n",
    "    \n",
    "\n",
    "# End date\n",
    "    end_list = []\n",
    "    \n",
    "    for date in surrogate_soup.find_all('td', class_='labelColumn'):\n",
    "        if 'Global end of trial date' in date.text:\n",
    "            v_date = date.find_next_sibling('td', class_='valueColumn')\n",
    "            if v_date:\n",
    "                d_text = v_date.div.get_text(strip=True)\n",
    "                end_list.append(d_text)\n",
    "        \n",
    "            if len(end_list) ==1:\n",
    "                all_characteristics_df.iloc[z,4] = end_list[0]    \n",
    "\n",
    "# Number of participants\n",
    "    subj_list = []\n",
    "    \n",
    "    for m_subj in surrogate_soup.find_all('td', class_='labelColumn'):\n",
    "        if 'Worldwide total number of subjects' in m_subj.text:\n",
    "            v_subj = m_subj.find_next('td', class_='valueColumn')\n",
    "            if v_subj:\n",
    "                p_text = v_subj.div.get_text(strip=True)\n",
    "                subj_list.append(p_text)\n",
    "                \n",
    "        if len(subj_list)==1:\n",
    "            all_characteristics_df.iloc[z,5] = subj_list[0]\n",
    "\n",
    "# Primary endpoint\n",
    "    point_list = []\n",
    "\n",
    "    for m_primary in surrogate_soup:\n",
    "        if 'Primary: ' in m_primary.text:\n",
    "            v_primary = m_primary('h3')\n",
    "            if v_primary:\n",
    "                point_list.append(v_primary)\n",
    "        \n",
    "        if len(point_list)==1:\n",
    "            all_characteristics_df.iloc[z,6] = point_list[0] \n",
    "            break \n",
    "\n",
    "# Endpoint description\n",
    "     description_list = []\n",
    "\n",
    "    for description in surrogate_soup.find_all('td', class_='labelColumn'):\n",
    "        if 'End point description' in description.text:\n",
    "            v_description = description.find_next('td', class_='valueColumn')\n",
    "            if v_description:\n",
    "                o_description = v_description.div.get_text(strip=True)\n",
    "                print(o_description)\n",
    "                description_list.append(o_description)\n",
    "      if len(description_list) ==1:\n",
    "            characteristics_df.iloc[z,] = description_list[0]\n",
    "\n",
    "# Treatment\n",
    "    switch = False\n",
    "\n",
    "    for m_drug in surrogate_soup.find_all('td', class_='labelColumn'):\n",
    "        if 'Arm type' in m_drug.text:\n",
    "            step_drug = m_drug.find_next('td', class_='valueColumn')\n",
    "            if 'Active comparator' in step_drug.text:\n",
    "                switch = False \n",
    "            else: \n",
    "                switch = True\n",
    "            \n",
    "        if switch == True:\n",
    "            if 'Investigational medicinal product name' in m_drug.text:\n",
    "                stepp_text = m_drug.find_next('td', class_='valueColumn')\n",
    "                print(step_drug)\n",
    "                print(stepp_text)\n",
    "                all_characteristics_df.iloc[z,7] = stepp_text.text\n",
    "                break\n",
    "           \n",
    "            \n",
    "# Long-term follow-up?\n",
    "    lt_list = []\n",
    "\n",
    "    for m_lt in surrogate_soup.find_all('td'):\n",
    "        if 'Long term follow-up planned' in m_lt.text:\n",
    "            v_lt = m_lt.find_next('td', class_='valueColumn')\n",
    "            print(m_lt)\n",
    "            print(v_lt)\n",
    "            if v_lt:\n",
    "                l_text = v_lt.div.get_text(strip=True)\n",
    "                lt_list.append(l_text)\n",
    "        \n",
    "        if len(lt_list)==1:\n",
    "            all_characteristics_df.iloc[z,8] = lt_list[0]\n",
    "\n",
    "\n",
    "\n",
    "display(all_characteristics_df)\n",
    "\n",
    "all_characteristics_df.to_csv('ns_protocols', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check success of extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_protocols = pd.read_csv()\n",
    "ns_protocols.sample(40, random_state=4).to_csv('success_check_euctns.csv', index=False) # 20% of the dataframe \n",
    "# Manually checked each scraped section in the dataframe against the protocols on the EU clinical trials website, added new column 'Is_correct',\n",
    "# if only one characteristic was scraped incorrectly, whole scrape for that particular protocol was labelled false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_check = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(success_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_rate = success_check['is_correct'].mean() # Establishing point accuracy of the sample web scrape\n",
    "print(f\"Success Rate: {accuracy_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(success_check)\n",
    "successes = success_check['is_correct'].sum()\n",
    "\n",
    "ci_low, ci_upp = proportion_confint(successes, n, alpha=0.05, method='wilson') # Estimate confidence interval for range of how accurate the scraping is. Wilson method because of small sample size\n",
    "print(f\"95% Confidence Interval: [{ci_low:.2%}, {ci_upp:.2%}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "method1_clustering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
